<rss version="2.0"><channel>
<title>Oliver Webb's Webspace Thingy</title>
<link>https://oliverkwebb.github.io</link>
<language>en</language>
<item><title>Writing a UTF-8 safe AWK</title>
<link>https://oliverkwebb.github.ioarticles/utfawk.html</link>
<pubDate>Fri, 26 Apr 2024 00:00:00 -0500</pubDate>
<description>
&lt;p&gt;One of the things the toybox project prioritizes is unicode handling for it&amp;#8217;s
applications. This has kept things like &lt;a href=&quot;http://lists.landley.net/pipermail/toybox-landley.net/2023-October/029845.html&quot;&gt;the fully GNU compatible tr&lt;/a&gt;
from being promoted from the pending&amp;#47; directory for years because they
wish to break compatibility by making tr unicode safe. Toybox&amp;#8217;s plans for awk
are &lt;a href=&quot;http://lists.landley.net/pipermail/toybox-landley.net/2021-June/012453.html&quot;&gt;no different story&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Fortunately for any &lt;a href=&quot;https://www.github.com/raygard/wak&quot;&gt;awk implementation&lt;/a&gt;
attempting to get into toybox; Awk works with strings, while tr works with
characters. Awk does not regularly index into the strings it works with, and
when it does it only happens in a few functions. This means that if we want
to handle UTF-8, we can divide and conquer.&lt;/p&gt;
&lt;h3 id=&quot;what-a-utf-8-safe-awk-needs&quot;&gt;What a UTF-8 Safe awk needs&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&quot;https://man7.org/linux/man-pages/man1/gawk.1.html&quot;&gt;gawk(1) man page&lt;/a&gt; says
these 4 functions work on &amp;#8220;characters, not bytes&amp;#8221;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;substr()&lt;/li&gt;
&lt;li&gt;length()&lt;/li&gt;
&lt;li&gt;match()&lt;/li&gt;
&lt;li&gt;index()&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second addition awk book also mentions these:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;printf %c [STRING]&lt;/li&gt;
&lt;li&gt;printf %c [CODEPOINT]&lt;/li&gt;
&lt;li&gt;\u[CODEPOINT]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And finally, these work internally by indexing the string:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;toupper()&lt;/li&gt;
&lt;li&gt;tolower()&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That&amp;#8217;s &amp;#8220;divide&amp;#8221; out of the way, now lets conquer.&lt;/p&gt;
&lt;h3 id=&quot;implementing-a-utf-8-awk&quot;&gt;Implementing a UTF-8 Awk&lt;/h3&gt;
&lt;p&gt;A reminder that we are trying to add in UTF-8 support to a existing awk, not
make a new one with UTF-8 support.&lt;/p&gt;
&lt;p&gt;In a awk that is UTF-8 safe, all strings are indexed by a number of UTF-8
characters. While in C, all strings are indexed based off of bytes. This
means that for substr(), length(), match(), and index(). We need a way to
convert between the two. This can be done by two functions, one which counts
the bytes in a utf8 string, and another that counts the characters in a C byte
string. This work was &lt;a href=&quot;https://github.com/raygard/wak/commit/2e94cd3de8fb4d091ca19bb429cb4b2cb9d6a80e&quot;&gt;originally done by me&lt;/a&gt;
with 2 functions that acted as analogs to &lt;code&gt;mbrtowc()&lt;/code&gt; and &lt;code&gt;wcstombs()&lt;/code&gt; from libc.
And &lt;a href=&quot;https://github.com/raygard/wak/commit/2e94cd3de8fb4d091ca19bb429cb4b2cb9d6a80e&quot;&gt;Ray Gardner de-over-engineered&lt;/a&gt; these functions.&lt;/p&gt;
&lt;p&gt;As long as you have the ability to turn unicode codepoints back into strings,
\u[CODEPOINT] is a easy fix too. While the current digit you are reading is a
valid hexidecimal character, read that digit into a buffer. Then &lt;code&gt;strtol()&lt;/code&gt; to
turn that buffer into a codepoint, then convert that codepoint back into a string.
There are printf format escapes that print 1 utf8 character of a string.
Which in practice makes printf %c easier. The tolower() and toupper()
problem is more complex, but fundamentally involves taking a string, running
though it and running &lt;code&gt;towlower&amp;#47;upper()&lt;/code&gt; on it, expanding it when needed.
You can look at &lt;a href=&quot;https://github.com/raygard/wak/commit/2e94cd3de8fb4d091ca19bb429cb4b2cb9d6a80e&quot;&gt;the actual code which does this&lt;/a&gt;,
as that will explain it better than I could.&lt;/p&gt;
&lt;p&gt;FS&amp;#47;split() say that if the field separator is more than one character, it will be
treated as a regex. This in practice does not matter, since a multi-byte unicode
FS will never contain any special regexp syntax character.&lt;/p&gt;
&lt;p&gt;Writing in UTF-8 support into a already existing awk is a lot simpler than it seems.
wak needed less than 100 lines to make itself UTF-8 safe. Most of the hard part
is figuring out &lt;em&gt;what&lt;/em&gt; needs unicode handling.&lt;/p&gt;
</description></item>
<item><title>Replacing Neovim with vis</title>
<link>https://oliverkwebb.github.ioarticles/vis.html</link>
<pubDate>Wed, 17 Apr 2024 00:00:00 -0500</pubDate>
<description>
&lt;p&gt;Lately, I&amp;#8217;ve been unhappy with neovim and it&amp;#8217;s bloat. vi is a simple and beautiful tool by
itself, but it&amp;#8217;s most popular deviation vim has been bloated to the point of being unmanageable
the same way perl took the design of awk or C++ took the design of C and destroyed it.&lt;/p&gt;
&lt;p&gt;Neovim remedies this, but not by much. And in place it adds more bloat. And it&amp;#8217;s decision
on removing build configuration means that it can&amp;#8217;t be de-bloated in the spirit of tiny vim
builds.&lt;/p&gt;
&lt;p&gt;And the worst part of this, some of the bloat is actually useful. Bloated software has the
problem of &amp;#8220;Everyone only uses 20%, but it&amp;#8217;s always a different 20%&amp;#8221;. This makes the minimal
vi implementations hard to use. I &lt;em&gt;want&lt;/em&gt; syntax highlighting and colorization, I &lt;em&gt;want&lt;/em&gt; the
ability to batch process data with ex commands.  I &lt;em&gt;want&lt;/em&gt; the ability to select things with
visual mode. This disqualifies implementations like nextvi, nvi, and busybox vi.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://kakoune.org/&quot;&gt;Kakoune&lt;/a&gt; seems like a good alternative, with two massive problems:
- It&amp;#8217;s written in C++
- Constant compatibility breaks, this is a vi clone only in name&lt;/p&gt;
&lt;p&gt;I generally &lt;a href=&quot;https://harmful.cat-v.org/software/c++/&quot;&gt;don&amp;#8217;t trust C++ coders&lt;/a&gt; with writing minimal software.
And the willingness to break everything is probably a way of venting the fact that C++&amp;#8217;s selling point is
the fact that it&amp;#8217;s C compatible, and that restricts the language massively.&lt;/p&gt;
&lt;p&gt;What does this leave? There is apparently one editor called &lt;a href=&quot;https://github.com/martanne/vis&quot;&gt;vis&lt;/a&gt;
that&amp;#8217;s minimal, has a large amount of vim-isms, and is written in pure C with configuration able to
be done in lua. It only takes up a couple megabytes of space, while vim takes up 60 and neovim takes
up 40. It lacks things like the s, g, and v ex commands in favor of multi-cursor editing.&lt;/p&gt;
&lt;p&gt;vis also has inbuilt syntax highlighting, with a &lt;a href=&quot;https://github.com/martanne/vis/wiki/Themes&quot;&gt;selection of themes to use&lt;/a&gt;.
vis has inbuilt options for line numbering (including relative line numbering), tab to space conversion
And autoindenting (Although, Not very good autoindenting). It also has a semi-customize-able
status and keybindings bar via the lua API.&lt;/p&gt;
&lt;p&gt;Here are some features that aren&amp;#8217;t in vis &lt;em&gt;by default&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;#8220;gf&amp;#8221; motion&lt;/li&gt;
&lt;li&gt;Leading whitespace detection&lt;/li&gt;
&lt;li&gt;Some way to spellcheck&amp;#47;auto-complete&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let&amp;#8217;s look at these individually and see what vis can achieve.&lt;/p&gt;
&lt;p&gt;There are &lt;a href=&quot;https://github.com/martanne/vis/wiki/Plugins&quot;&gt;a lot of plugins&lt;/a&gt; to do these things:
- &lt;a href=&quot;https://repo.or.cz/vis-goto-file.git&quot;&gt;vis-goto-file&lt;/a&gt;: for the &amp;#8220;gf&amp;#8221; motion,
- &lt;a href=&quot;https://github.com/erf/vis-highlight&quot;&gt;vis-highlight&lt;/a&gt;: for leading white-space detection.
- &lt;a href=&quot;https://gitlab.com/muhq/vis-spellcheck&quot;&gt;vis-spellcheck&lt;/a&gt;: for spellchecking.&lt;/p&gt;
&lt;p&gt;There are also lua plugins I didn&amp;#8217;t even know I wanted until now, like the ability to auto-format
and edit markdown tables with &lt;a href=&quot;https://www.thyssentishman.com/git/vis-tables/log.html&quot;&gt;vis-tables&lt;/a&gt;.
And backups that are stored in a reasonable place with &lt;a href=&quot;https://github.com/roguh/vis-backup&quot;&gt;vis-backup&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;That is not to say, vis is not without problems. For example, it is convenient to have the
cursor show up as a bar on insert mode, but show as a block on normal mode, so that you can
tell what mode you are in without looking at the status bar. This would normally be a simple
print statement on changing of modes. But for whatever reason (I think due to the fact that
there is multiple cursor support in vis). This does not change anything.&lt;/p&gt;
&lt;p&gt;If you do not like how bloated and large vim and it&amp;#8217;s forks are. But find the features that
vim provides useful, Vis includes many but not all vim-isms while still being elegant and
versatile.&lt;/p&gt;
</description></item>
<item><title>Making A static site generator with `make`</title>
<link>https://oliverkwebb.github.ioarticles/makessg.html</link>
<pubDate>Sat, 13 Apr 2024 00:00:00 -0500</pubDate>
<description>
&lt;p&gt;When making my website, generating static webpages for
my blogs and articles was a big concern. I want to be able
to manipulate templates and sytlesheets easily and have that
translate to my articles and content. HTML, to put it simply,
sucks for this work.&lt;/p&gt;
&lt;p&gt;The solution is static site generation, which is analogous to
ahead of time compilation. There are a variety of tools that
can be used for this. &lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt; is the one GitHub endorses,
the problem I have with that is that it is written in Ruby,
which means that I&amp;#8217;d have to pull in megabytes of extra
dependencies and slow the building process down for something
that ultimately takes away control from me.&lt;/p&gt;
&lt;p&gt;What I need is something that is efficient, customizable, and
fast. And above all, simplistic. This is where &lt;code&gt;make&lt;/code&gt; comes into
the picture.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;make&lt;/code&gt; takes a &amp;#8220;makefile&amp;#8221; with a list of rules. Each rule has a
list of commands to run. And you can do &lt;code&gt;make rule&lt;/code&gt; to run the
commands in that rule. If you specify a list of rules, it will
run all those rules, if you specify no rules, it will run the
first rule specified in the makefile (commonly, this rule is
called &amp;#8220;all&amp;#8221;)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat Makefile
foo:
    echo bar
baz:
    echo foo
$ make foo baz
echo bar
bar
echo foo
foo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Make will list the commands it runs as it runs them, and will
abort if a command returns non-zero. Printing the command it
runs can be disabled by placing &lt;code&gt;@&lt;/code&gt; at the start of the command.
And aborting on failure of a command can be disabled by placing &lt;code&gt;-&lt;/code&gt;
at the start of the command&lt;/p&gt;
&lt;p&gt;Additionally, you can refer to &lt;a href=&quot;https://man7.org/linux/man-pages/man7/environ.7.html&quot;&gt;environment variables&lt;/a&gt; in your makefile,
and assign them on the command line or in your makefile.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat Makefile
BAZ=123
foo:
    @echo $(BAR) $(BAZ)
baz:
    -false
$ make baz foo BAR=abc
abc 123
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This allows for macros and the quick running of commands without manually typing
in the build commands. But this is not where the true magic of make is.&lt;/p&gt;
&lt;p&gt;A rule is not just a name for a macro that you type in on the command line,
it is a pattern. And more importantly, it is a filename unless said otherwise.
You can also specify prerequisites for running a rule. So you can say &lt;code&gt;a: b c&lt;/code&gt;,
which means that rule b and c have to run before a. You can specify that a
rule is not a filename by putting a line that says &lt;code&gt;.PHONY: [rule1] [rule2]&lt;/code&gt;.
This means that &lt;code&gt;rule1&lt;/code&gt; and &lt;code&gt;rule2&lt;/code&gt; will always run when called.&lt;/p&gt;
&lt;p&gt;Finally, if a rule:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Is an existing file&lt;/li&gt;
&lt;li&gt;Has prerequisite rules that are all files&lt;/li&gt;
&lt;li&gt;All prerequisite files &amp;#8220;last changed&amp;#8221; date are older than the main file&amp;#8217;s&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The rule is considered completed, and any commands from it are not ran.&lt;/p&gt;
&lt;p&gt;This makes AOT compilation with object files much faster. Since you can
change one file, and it will detect that all the other &amp;#8220;object files&amp;#8221; are newer
then their respective source files &lt;em&gt;except&lt;/em&gt; the one you have changed. And it
will automatically build only that changed file.&lt;/p&gt;
&lt;p&gt;But having a rule for each source file seems excessive, right? This is why rules
are patterns. The character &lt;code&gt;%&lt;/code&gt; means &amp;#8220;anything&amp;#8221; and is analogous to
&lt;code&gt;*&lt;/code&gt; in shell &lt;a href=&quot;https://man7.org/linux/man-pages/man3/glob.3.html&quot;&gt;globbing&lt;/a&gt;, this allows us to create a rule for all &lt;code&gt;.c&lt;/code&gt; files&lt;/p&gt;
&lt;p&gt;But how will we refer to the source file in the build command? This is why there
are special variables in make; You can use &lt;code&gt;$&amp;#60;&lt;/code&gt; to refer to your first item in
the list of prerequisites, and &lt;code&gt;$@&lt;/code&gt; to refer to your rule name. Note this is
not the pattern that the specified rule matched, it is the rule that matched
the pattern.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;%.o: %.c
    $(CC) $(CFLAGS) $&amp;#60; -o $@
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you run &lt;code&gt;make main.o&lt;/code&gt;, it will detect that &amp;#8220;main.o&amp;#8221; matches the pattern 
rule &amp;#8220;%.o&amp;#8221;, next it will check if the file &amp;#8220;main.c&amp;#8221; is there. If it is not and
there is no rule that matches &amp;#8220;main.c&amp;#8221;, it will not know what to do and fail.
Otherwise, if the file &amp;#8220;main.c&amp;#8221; is older than the file &amp;#8220;main.o&amp;#8221;, it will assume
no changes have been made and there is therefore nothing to be done. Then, it
will run the build command, refereeing to the variable CC (By default &amp;#8220;c99&amp;#8221;),
passing in the flags CFLAGS, and running this on the prerequisite files name
&amp;#8220;main.c&amp;#8221; outputting to our rule name, the file &amp;#8220;main.o&amp;#8221;.&lt;/p&gt;
&lt;p&gt;This is the essence of &lt;code&gt;make&lt;/code&gt;&amp;#8217;s functionality, and is the useful stuff POSIX
specifies. But there are other things in GNU make, like the ability to add a
prefix to all items in a list with the addprefix function, or the wildcard
function to get all items and put them in a list. Functions are specified in
variable definitions and arguments are separated by commas. So that evaluating
&lt;code&gt;$(addprefix 123, a b c)&lt;/code&gt; will return &amp;#8220;123a 123b 123c&amp;#8221;.&lt;/p&gt;
&lt;p&gt;Since the problem of turning markdown files into html files is similar to the
problem of turning source files into object files, we can create a simple rule
that does 99% of our work.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;%.html: %.md
    $(MARKDOWN) $(MDFLAGS) $&amp;#60; &amp;#62;&amp;#62; $@
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But markdown compilers don&amp;#8217;t usally generate HTML boilerplate, and we might
want to import a stylesheet, and maybe save to a &amp;#8220;dist&amp;#8221; directory. So that
if we have a &amp;#8220;index.md&amp;#8221; file, it will compile to &lt;code&gt;$(DIST)&amp;#47;index.html&lt;/code&gt;, this
is no issue for us.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$(DIST)&amp;#47;%.html: %.md
    cat $(TEMPLATES)&amp;#47;begin.html &amp;#62; $@
    $(MARKDOWN) $(MDFLAGS) $&amp;#60; &amp;#62;&amp;#62; $@
    cat $(TEMPLATES)&amp;#47;end.html &amp;#62;&amp;#62; $@
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice how % goes after the &lt;code&gt;$(DIST)&lt;/code&gt; prefix, which means that referencing
it in our prerequisite list will not add it as a prefix.&lt;/p&gt;
&lt;p&gt;We have our workhorse rule, but, &amp;#8220;how do we put this together?&amp;#8221;,
we can specify variables for our markdown compiler (in this example, I used
&lt;code&gt;lowdown&lt;/code&gt;), and scan for files in a source directory using
the wildcard command. Making them valid rule names by substituting .md prefixes
with .html ones, and adding the prefix &lt;code&gt;$(DIST)&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DIST=dist
TEMPLATES=templ
MARKDOWN=lowdown

PAGES=$(wildcard pages&amp;#47;*.md)
PDEST=$(addprefix $(DIST)&amp;#47;, $(patsubst %.md, %.html, $(PAGES)))

# ${VAR} breaks down VAR into a list of rules
all: ${PDEST}

$(DIST)&amp;#47;%.html: pages&amp;#47;%.md
    cat $(TEMPLATES)&amp;#47;begin.html &amp;#62; $@
    $(MARKDOWN) $(MDFLAGS) $&amp;#60; &amp;#62;&amp;#62; $@
    cat $(TEMPLATES)&amp;#47;end.html &amp;#62;&amp;#62; $@
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want to add a conditional generation step for the index, you
can put a &lt;code&gt;if [ $@ = $(DIST)&amp;#47;index.html ]; then .&amp;#47;gen &amp;#62;&amp;#62; $@; fi&lt;/code&gt; rule in
your main rule. You can add almost infinite customization to this with
conditionals or extra rules.&lt;/p&gt;
&lt;p&gt;Additional Resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.gnu.org/software/make/manual/make.pdf&quot;&gt;GNU make manual&lt;/a&gt;,&lt;/li&gt;
&lt;/ul&gt;
</description></item>
</channel></rss>
